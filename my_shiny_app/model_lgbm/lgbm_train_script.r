library(dplyr)
library(lightgbm)
library(caret)
library(ggplot2)
library(readr)

# --- è®Šæ•¸ç´¢å¼• ---
# df        ï¼šå®Œæ•´è³‡æ–™ï¼ˆdata.frameï¼‰
# train_df  ï¼šè¨“ç·´è³‡æ–™ï¼ˆå«ç›®æ¨™å€¼ï¼Œdata.frameï¼‰
# test_df   ï¼šæ¸¬è©¦è³‡æ–™ï¼ˆå«ç›®æ¨™å€¼ï¼Œdata.frameï¼‰
# test_mat  ï¼šæ¸¬è©¦è³‡æ–™çš„ç´”æ•¸å€¼ç‰¹å¾µçŸ©é™£ï¼ˆä¸å«ç›®æ¨™å€¼ï¼‰
# -- k-fold CV è®Šæ•¸ç´¢å¼• ---
# train_data: æ¯ä¸€fold çš„è¨“ç·´è³‡æ–™ï¼ˆdata.frameï¼‰
# valid_data: æ¯ä¸€fold çš„é©—è­‰è³‡æ–™ï¼ˆdata.frameï¼‰
# mat       ï¼šæ¯ä¸€fold è¨“ç·´è³‡æ–™çš„ç´”æ•¸å€¼ç‰¹å¾µçŸ©é™£ï¼ˆä¸å«ç›®æ¨™å€¼ï¼‰
# valid_mat ï¼šæ¯ä¸€fold é©—è­‰è³‡æ–™çš„ç´”æ•¸å€¼ç‰¹å¾µçŸ©é™£ï¼ˆä¸å«ç›®æ¨™å€¼ï¼‰
# --- æ¨¡å‹åƒæ•¸ ---
# categorical_colsï¼šé¡åˆ¥æ¬„ä½çš„åç¨±ï¼ˆcharacter vectorï¼‰
# to_removeï¼šè¦ç§»é™¤çš„ç‰¹å¾µåç¨±ï¼ˆcharacter vectorï¼‰
# --- æé†’ ---
# data.matrix()ï¼šæœƒæŠŠè³‡æ–™è¡¨è½‰æˆç´”æ•¸å€¼çš„çŸ©é™£ï¼ˆfactor æœƒè‡ªå‹•ç·¨ç¢¼æˆæ•¸å­—ï¼‰
# æœ€çµ‚ä½¿ç”¨ç‰¹å¾µç‚º mat, valid_mat, test_mat çš„æ¬„ä½åç¨±
# å¯ç”± print(importance)ä¾† æŸ¥çœ‹ç‰¹å¾µé‡è¦æ€§è·Ÿæœ‰ç”¨åˆ°çš„ç‰¹å¾µ


# 1.æŒ‡å®šè¦è®€å–çš„æ¬„ä½
use_columns <- c(
  "é„‰é®å¸‚å€", "ç¸½é¡å…ƒ", "ç§Ÿè³ƒå¹´æœˆæ—¥",
  "å‡ºç§Ÿå‹æ…‹",  
  "ç§Ÿè³ƒå±¤æ¬¡(å››é¡)", "ç¸½æ¨“å±¤æ•¸", "å»ºç‰©å‹æ…‹", 
  "äº¤æ˜“ç­†æ£Ÿæ•¸-åœŸåœ°", "äº¤æ˜“ç­†æ£Ÿæ•¸-å»ºç‰©",
  "ç§Ÿè³ƒä½å®…æœå‹™", "ç§Ÿè³ƒå¤©æ•¸",
  "æœ‰ç„¡ç®¡ç†çµ„ç¹”", "æœ‰ç„¡ç®¡ç†å“¡", "æœ‰ç„¡é™„å‚¢ä¿±","æœ‰ç„¡é›»æ¢¯", 
  "å»ºç‰©ç¾æ³æ ¼å±€-æˆ¿", "å»ºç‰©ç¾æ³æ ¼å±€-å»³","å»ºç‰©ç¾æ³æ ¼å±€-è¡›", "å»ºç‰©ç¾æ³æ ¼å±€-éš”é–“", 
  "å»ºç‰©ç¸½é¢ç©å¹³æ–¹å…¬å°º", 
  "å±‹é½¡",
  "å»ºæåˆ†é¡",
  "é™„å±¬è¨­å‚™-å†·æ°£", "é™„å±¬è¨­å‚™-ç†±æ°´å™¨", "é™„å±¬è¨­å‚™-æ´—è¡£æ©Ÿ","é™„å±¬è¨­å‚™-é›»è¦–æ©Ÿ", "é™„å±¬è¨­å‚™-å†°ç®±", "é™„å±¬è¨­å‚™-ç“¦æ–¯æˆ–å¤©ç„¶æ°£", "é™„å±¬è¨­å‚™-æœ‰ç·šé›»è¦–", "é™„å±¬è¨­å‚™-ç¶²è·¯",
  "æ·é‹ç«™è·é›¢(å…¬å°º)",
  "æ–‡æ¹–ç·š", "æ·¡æ°´ä¿¡ç¾©ç·š", "æ–°åŒ—æŠ•æ”¯ç·š", "æ¾å±±æ–°åº—ç·š", "å°ç¢§æ½­æ”¯ç·š", 
  "ä¸­å’Œæ–°è˜†ç·š", "æ¿å—ç·š", "ç’°ç‹€ç·š", "é™„è¿‘å»ºç‰©å–®ä½æˆäº¤å‡åƒ¹"
) 

# 2. ç¶“éæ¸¬è©¦ï¼Œç‰¹å¾µå…¨ç•™ä¸‹
to_remove <- c()
# ç”¨ setdiff() ç§»é™¤æŒ‡å®šæ¬„ä½
use_columns_clean <- setdiff(use_columns, to_remove)


# 3. è®€å–è³‡æ–™ä¸¦ç¯©é¸æ¬„ä½
full_data <- read_csv("dataset/rent_mrg.csv", show_col_types = FALSE)
df <- full_data %>% select(all_of(use_columns_clean))

# 4. ç¯©æ‰ã€Œå¤©æ•¸å¤ªçŸ­ã€çš„è³‡æ–™ï¼ˆå¦‚ < 30 å¤©ï¼‰ï¼Œä»¥åŠå¡«è£œç¼ºå¤±å€¼
df <- df %>% filter(ç§Ÿè³ƒå¤©æ•¸ >= 30)
df$å‡ºç§Ÿå‹æ…‹[is.na(df$å‡ºç§Ÿå‹æ…‹)] <- "æœªçŸ¥"
df$ç§Ÿè³ƒä½å®…æœå‹™[is.na(df$ç§Ÿè³ƒä½å®…æœå‹™)] <- "æœªçŸ¥"
df$ç§Ÿè³ƒå¹´æœˆæ—¥ <- as.numeric(df$ç§Ÿè³ƒå¹´æœˆæ—¥)

# 5. å°‡ one-hot æ·é‹æ¬„ä½åˆä½µæˆä¸€æ¬„ï¼ˆæ–¹ä¾¿åˆ†æï¼‰
df <- df %>%
  mutate(æ·é‹ç·š = case_when(
    æ–‡æ¹–ç·š == 1 ~ "æ–‡æ¹–ç·š",
    æ·¡æ°´ä¿¡ç¾©ç·š == 1 ~ "æ·¡æ°´ä¿¡ç¾©ç·š",
    æ–°åŒ—æŠ•æ”¯ç·š == 1 ~ "æ–°åŒ—æŠ•æ”¯ç·š",
    æ¾å±±æ–°åº—ç·š == 1 ~ "æ¾å±±æ–°åº—ç·š",
    å°ç¢§æ½­æ”¯ç·š == 1 ~ "å°ç¢§æ½­æ”¯ç·š",
    ä¸­å’Œæ–°è˜†ç·š == 1 ~ "ä¸­å’Œæ–°è˜†ç·š",
    æ¿å—ç·š == 1 ~ "æ¿å—ç·š",
    ç’°ç‹€ç·š == 1 ~ "ç’°ç‹€ç·š",
    TRUE ~ "ç„¡æ·é‹"
  )) %>%
  select(-c(æ–‡æ¹–ç·š, æ·¡æ°´ä¿¡ç¾©ç·š, æ–°åŒ—æŠ•æ”¯ç·š, æ¾å±±æ–°åº—ç·š, å°ç¢§æ½­æ”¯ç·š, 
            ä¸­å’Œæ–°è˜†ç·š, æ¿å—ç·š, ç’°ç‹€ç·š)) # ç§»é™¤åŸ one-hot æ¬„ä½


# 6. æŒ‡å®šåˆ†é¡æ¬„ä½ ä¸¦ç¯©æ‰æ²’ç”¨çš„features
categorical_cols <- c("é„‰é®å¸‚å€", "å‡ºç§Ÿå‹æ…‹", "ç§Ÿè³ƒå±¤æ¬¡(å››é¡)", "å»ºç‰©å‹æ…‹", "ç§Ÿè³ƒä½å®…æœå‹™", "æ·é‹ç·š", "å»ºæåˆ†é¡")
categorical_cols <- setdiff(categorical_cols, to_remove)
# å°‡æŒ‡å®šæ¬„ä½è½‰æ›ç‚º factorï¼ˆé¡åˆ¥å‹è³‡æ–™ï¼‰
df[categorical_cols] <- lapply(df[categorical_cols], factor)


# 7. train/test splitï¼Œå…ˆåˆ†ç®± stratify
set.seed(42)
df$price_bin <- cut(df$ç¸½é¡å…ƒ,
                    breaks = quantile(df$ç¸½é¡å…ƒ, probs = seq(0, 1, 0.2), na.rm = TRUE),
                    include.lowest = TRUE)
train_idx <- createDataPartition(df$price_bin, p = 0.8, list = FALSE)
train_df <- df[train_idx, ] %>% select(-price_bin)
test_df  <- df[-train_idx, ] %>% select(-price_bin)


# 8. åœ¨ train_df ä¸Šåš K-fold Cross Validation (tune è¶…åƒæ•¸)
k <- 10
train_df$price_bin <- cut(train_df$ç¸½é¡å…ƒ,
                          breaks = quantile(train_df$ç¸½é¡å…ƒ, probs = seq(0, 1, length.out = k + 1), na.rm = TRUE),
                          include.lowest = TRUE)
folds <- createFolds(train_df$price_bin, k = k, returnTrain = TRUE)
train_df <- train_df %>% select(-c(price_bin))

# 9. å®šç¾©è¶…åƒæ•¸æœå°‹ç©ºé–“
grid <- expand.grid(
  num_leaves = c(31),  # å¯æ ¹æ“šéœ€è¦èª¿æ•´
  learning_rate = c(0.05),
  feature_fraction = c(0.8),
  min_data_in_leaf = c(20),  # å¯æ ¹æ“šéœ€è¦èª¿æ•´
  nrounds = c(500)  # å¯æ ¹æ“šéœ€è¦èª¿æ•´
)

# åˆå§‹åŒ–æœ€ä½³åƒæ•¸èˆ‡çµæœå„²å­˜
best_rmse <- Inf
best_params <- list()
results_k_fold_tv <- data.frame()


# 10. é€çµ„è¶…åƒæ•¸åš K-fold CV
for (i in 1:nrow(grid)) {
  params <- as.list(grid[i, ])
  rmse_list <- c()
  mape_list <- c()
  medape_list <- c()
  sdpe_list <- c()

  for (f in 1:length(folds)) {
    train_data <- train_df[folds[[f]], ]
    valid_data <- train_df[-folds[[f]], ]

    # è½‰æˆçŸ©é™£å‹æ…‹ï¼ˆé™¤äº† y è®Šæ•¸ä»¥å¤–ï¼‰
    mat <- data.matrix(train_data %>% select(-ç¸½é¡å…ƒ))
    colnames(mat) <- setdiff(names(train_data), "ç¸½é¡å…ƒ")
    
    valid_mat <- data.matrix(valid_data %>% select(-ç¸½é¡å…ƒ))
    colnames(valid_mat) <- setdiff(names(valid_data), "ç¸½é¡å…ƒ")

    # è¨“ç·´è³‡æ–™ y å– log
    dtrain <- lgb.Dataset(data = mat,
                          label = log(train_data$ç¸½é¡å…ƒ),
                          categorical_feature = categorical_cols)
    dvalid <- lgb.Dataset(data = valid_mat,
                          label = log(valid_data$ç¸½é¡å…ƒ),
                          categorical_feature = categorical_cols)
    # è¨“ç·´æ¨¡å‹
    model <- lgb.train(
      params = c(params, list(objective = "regression", metric = "rmse")),
      data = dtrain,
      nrounds = params$nrounds,
      valids = list(valid = dvalid),
      verbose = -1,
      early_stopping_rounds = 100
    )

    # é æ¸¬çš„æ˜¯ log(price)ï¼Œè¦è½‰å›åŸæœ¬å–®ä½
    preds_logs <- predict(model, valid_mat)
    preds <- exp(preds_logs) # é‚„åŸç‚ºç§Ÿé‡‘é‡‘é¡ï¼ˆå…ƒï¼‰

    # è¨ˆç®—èª¤å·®ï¼ˆè·ŸåŸå§‹ç§Ÿé‡‘æ¯”ï¼‰
    rmse <- sqrt(mean((preds - valid_data$ç¸½é¡å…ƒ)^2))
    mape <- mean(abs(preds - valid_data$ç¸½é¡å…ƒ) / valid_data$ç¸½é¡å…ƒ)
    medape <- median(abs(preds - valid_data$ç¸½é¡å…ƒ) / valid_data$ç¸½é¡å…ƒ)
    sdpe <- sd(abs(preds - valid_data$ç¸½é¡å…ƒ) / valid_data$ç¸½é¡å…ƒ)

    # è¨ˆç®—èª¤å·®ï¼ˆè·ŸåŸå§‹ç§Ÿé‡‘æ¯”ï¼‰
    rmse_list <- c(rmse_list, rmse)
    mape_list <- c(mape_list, mape)
    medape_list <- c(medape_list, medape)
    sdpe_list <- c(sdpe_list, sdpe)
  }

  avg_rmse <- mean(rmse_list)
  avg_mape <- mean(mape_list)
  avg_medape <- mean(medape_list)
  avg_sdpe <- mean(sdpe_list)

  cat(sprintf("Grid %d â†’ CV RMSE: %.2f | MAPE: %.4f | MEAPE: %4f | SDPE: %4f\n", i, avg_rmse, avg_mape, avg_medape, avg_sdpe))

  if (avg_rmse < best_rmse) {
    best_rmse <- avg_rmse
    best_params <- params
  }
}

cat("Best Parameters:\n")
print(best_params)


# 11. åœ¨å®Œæ•´ train_df ä¸Šè¨“ç·´æœ€çµ‚æ¨¡å‹
train_mat <- data.matrix(train_df %>% select(-ç¸½é¡å…ƒ))
colnames(train_mat) <- setdiff(names(train_df), "ç¸½é¡å…ƒ")
final_model <- lgb.train(
  params = c(best_params, list(objective = "regression", metric = "rmse")),
  data = lgb.Dataset(data = train_mat, 
                    label = log(train_df$ç¸½é¡å…ƒ),
                    categorical_feature = categorical_cols),
  nrounds = best_params$nrounds,
  verbose = -1
)


# 12. ç”¨ test_df é æ¸¬ï¼Œè¨ˆç®—å„ç¨®èª¤å·®
test_mat <- data.matrix(test_df %>% select(-ç¸½é¡å…ƒ))
colnames(test_mat) <- setdiff(names(test_df), "ç¸½é¡å…ƒ")

test_preds_log <- predict(final_model, test_mat)
test_preds <- exp(test_preds_log)

test_rmse <- sqrt(mean((test_preds - test_df$ç¸½é¡å…ƒ)^2))
test_mape <- mean(abs(test_preds - test_df$ç¸½é¡å…ƒ) / test_df$ç¸½é¡å…ƒ)
test_meape <- median(abs(test_preds - test_df$ç¸½é¡å…ƒ) / test_df$ç¸½é¡å…ƒ)
test_sdpe <- sd(abs(test_preds - test_df$ç¸½é¡å…ƒ) / test_df$ç¸½é¡å…ƒ)

cat("\nğŸ¯ Final Test RMSE:", round(test_rmse, 2), "\n")
cat("ğŸ¯ Final Test MAPE:", round(test_mape, 4), "\n")
cat("ğŸ¯ Final Test MEAPE:", round(test_meape, 4), "\n")
cat("ğŸ¯ Final Test SDPE:", round(test_sdpe, 4), "\n")

# 13. è¼¸å‡ºé æ¸¬çµæœè‡³ csv
final_result <- test_df %>%
  mutate(Predicted = test_preds,
         AbsError = abs(Predicted - ç¸½é¡å…ƒ),
         MAPE = abs(Predicted - ç¸½é¡å…ƒ) / ç¸½é¡å…ƒ)
write.csv(final_result, "lgbm_model_result_on_all_features.csv", row.names = FALSE)  # å¯ç”¨æ–¼å¾ŒçºŒåˆ†æ

# 14. å–å¾— feature importance
importance <- lgb.importance(final_model, percentage = TRUE)
importance$Gain <- format(importance$Gain, scientific = FALSE, digits = 4)
importance$Cover <- format(importance$Cover, scientific = FALSE, digits = 4)
importance$Frequency <- format(importance$Frequency, scientific = FALSE, digits = 4)
print(importance)

# 15. å­˜ä¸‹æ¨¡å‹ï¼ˆç¯„ä¾‹: å­˜æˆ txt æ ¼å¼ï¼‰
lgb.save(final_model, "final_lgbm_model.txt")  # é€™è¡Œæœƒå­˜æˆ .txtï¼Œå¯ä»¥ç”¨ lgb.load() è¼‰å›
# 16. å­˜ä¸‹ç‰¹å¾µé †åº
writeLines(colnames(train_mat), "lgbm_feature_order.txt")
# 17. å­˜ä¸‹æ‰€æœ‰é¡åˆ¥æ¬„ä½çš„ level order
saveRDS(lapply(train_df[, categorical_cols], levels), "factor_levels.rds")

